{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "olympic-writer",
   "metadata": {},
   "source": [
    "# Bees VS Wasps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-layout",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas\n",
    "\n",
    "Essas são todas as bibliotecas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thirty-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, mean_squared_error\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-durham",
   "metadata": {},
   "source": [
    "## Pré-processamento\n",
    "\n",
    "Aqui vem toda a parte de pré-processamento das imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unexpected-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(row_id, root=\"datasets/\"):\n",
    "    \"\"\"\n",
    "        Opens the image, and returns the image as a numpy array.\n",
    "    \"\"\"\n",
    "    filename = row_id.replace(\"\\\\\", \"/\")\n",
    "    file_path = os.path.join(root, filename)\n",
    "    img = Image.open(file_path)\n",
    "    return np.array(img)\n",
    "\n",
    "\n",
    "def create_features(img):\n",
    "    # flatten three channel color image\n",
    "    color_features = img.flatten()\n",
    "    # convert image to grayscale\n",
    "    gray_image = rgb2gray(img)\n",
    "    # get HOG features from grayscale image\n",
    "    hog_features = hog(gray_image, block_norm='L2-Hys',\n",
    "                       pixels_per_cell=(16, 16))\n",
    "    # combine color and hog features into a single array\n",
    "    flat_features = np.hstack((color_features, hog_features))\n",
    "    return flat_features\n",
    "\n",
    "\n",
    "def create_feature_matrix(label_dataframe, total_dados):\n",
    "    features_list = []\n",
    "    # contadores de limite de dados\n",
    "    total_bees = 0\n",
    "    total_wasp = 0\n",
    "\n",
    "    for _, row in label_dataframe.iterrows():\n",
    "        # só considera casos onde é vespa ou abelha e com qualidade de foto boa\n",
    "        if ((row.is_wasp == 1 and total_wasp < total_dados) or (row.is_bee == 1 and total_bees < total_dados)) and row.photo_quality == 1:\n",
    "            if row.is_wasp == 1:\n",
    "                total_wasp = total_wasp + 1\n",
    "            else:\n",
    "                total_bees = total_bees + 1\n",
    "\n",
    "            # load image\n",
    "            img = get_image(row.path)\n",
    "            # get features for image\n",
    "            image_features = create_features(img)\n",
    "            features_list.append(image_features)\n",
    "\n",
    "    # convert list of arrays into a matrix\n",
    "    feature_matrix = np.zeros([len(features_list), len(\n",
    "        max(features_list, key=lambda x: len(x)))])\n",
    "    for i, j in enumerate(features_list):\n",
    "        feature_matrix[i][0:len(j)] = j\n",
    "\n",
    "    return feature_matrix\n",
    "\n",
    "\n",
    "def load_bvsw(total_dados=50):\n",
    "    print(\"Abrindo arquivo...\")\n",
    "    labels = pd.read_csv(\"datasets/labels.csv\", index_col=0)\n",
    "\n",
    "    # verifica limite de dados\n",
    "    if total_dados > 4000:\n",
    "        total_dados = 4000\n",
    "\n",
    "    total_dados = total_dados // 2\n",
    "\n",
    "    print(\"Criando matriz de features...\")\n",
    "    feature_matrix = create_feature_matrix(labels, total_dados)\n",
    "\n",
    "    # define standard scaler\n",
    "    ss = StandardScaler()\n",
    "    # run this on our feature matrix\n",
    "    print(\"Padronizando dados...\")\n",
    "    bees_stand = ss.fit_transform(feature_matrix)\n",
    "\n",
    "    pca = PCA(n_components=min(500, total_dados*2))\n",
    "    # use fit_transform to run PCA on our standardized matrix\n",
    "    print(\"Rodando PCA (esse processo pode demorar um pouco)...\")\n",
    "    bees_pca = pca.fit_transform(bees_stand)\n",
    "    # look at new shape\n",
    "    print('Matriz de PCA concluída com formato: ', bees_pca.shape)\n",
    "\n",
    "    classes = np.concatenate((np.ones(total_dados), np.zeros(total_dados)))\n",
    "\n",
    "    return bees_pca, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-crisis",
   "metadata": {},
   "source": [
    "## Classificação\n",
    "\n",
    "Agora, a parte de definição dos modelos.\n",
    "\n",
    "A função a seguir define um modelo de acordo com a opção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sudden-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escolhe_modelo(escolha):\n",
    "    if escolha == '1':\n",
    "        return SVC(kernel='linear', probability=True, random_state=42)\n",
    "    elif escolha == '2':\n",
    "        return GaussianNB()\n",
    "    elif escolha == '3':\n",
    "        return DecisionTreeClassifier(random_state=42)\n",
    "    else:\n",
    "        print(\"Opção não existe! Terminando...\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-marine",
   "metadata": {},
   "source": [
    "Agora, deve-se escolher o modelo e a forma de validação, de acordo com as opções:\n",
    "\n",
    "**Modelos:**\n",
    "1. SVM;\n",
    "2. Naive Bayes;\n",
    "3. Árvore de decisão.\n",
    "\n",
    "**Validação:**\n",
    "1. Holdout repetido;\n",
    "2. KFold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "executive-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "escolha = 1 #modelo\n",
    "validacao = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-offer",
   "metadata": {},
   "source": [
    "Também, definir a quantidade de imagens que serão usadas para classificação e quantidade de repetições do método de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "selective-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantidade_dados = 500  # máximo é 4000\n",
    "repeticoes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-growing",
   "metadata": {},
   "source": [
    "Agora, os dados são carregados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "clinical-rouge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abrindo arquivo...\n",
      "Criando matriz de features...\n",
      "Padronizando dados...\n",
      "Rodando PCA (esse processo pode demorar um pouco)...\n",
      "Matriz de PCA concluída com formato:  (500, 500)\n"
     ]
    }
   ],
   "source": [
    "entrada, saida = load_bvsw(quantidade_dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-praise",
   "metadata": {},
   "source": [
    "Segue o processo de predição:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "varied-gateway",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e967c7a699a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# divide em sets de treino e teste\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     entrada_treino, entrada_teste, saida_treino, saida_teste = train_test_split(entrada,\n\u001b[0m\u001b[1;32m     46\u001b[0m                                                                                 \u001b[0msaida\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                                                                                 \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# para uso da validacao\n",
    "acertos = []\n",
    "aucs = []\n",
    "mses = []\n",
    "# pra plot de melhor roc\n",
    "falsos_positivos = []\n",
    "verdadeiros_positivos = []\n",
    "\n",
    "if validacao == '1':\n",
    "    kf = KFold(n_splits=repeticoes, shuffle=True)\n",
    "\n",
    "    for treino, teste in kf.split(entrada, saida):\n",
    "        # redefine modelo a cada repeticao\n",
    "        modelo = escolhe_modelo(escolha)\n",
    "\n",
    "        # fit model\n",
    "        modelo.fit(entrada[treino], saida[treino])\n",
    "\n",
    "        # generate predictions\n",
    "        predicao = modelo.predict(entrada[teste])\n",
    "\n",
    "        # calculate accuracy\n",
    "        acerto = accuracy_score(predicao, saida[teste])\n",
    "        # predict probabilities for entrada[teste] using predict_proba\n",
    "        probabilities = modelo.predict_proba(entrada[teste])\n",
    "        # select the probabilities for label 1.0\n",
    "        saida_proba = probabilities[:, 1]\n",
    "        # calculate false positive rate and true positive rate at different thresholds\n",
    "        false_positive_rate, true_positive_rate, _ = roc_curve(\n",
    "            saida[teste], saida_proba, pos_label=1)\n",
    "\n",
    "        # calculate AUC\n",
    "        roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "        # MSE\n",
    "        mse = mean_squared_error(saida[teste], predicao)\n",
    "\n",
    "        # guarda resultados\n",
    "        acertos.append(acerto)\n",
    "        aucs.append(roc_auc)\n",
    "        mses.append(mse)\n",
    "        falsos_positivos.append(false_positive_rate)\n",
    "        verdadeiros_positivos.append(true_positive_rate)\n",
    "else:\n",
    "    # divide em sets de treino e teste\n",
    "    entrada_treino, entrada_teste, saida_treino, saida_teste = train_test_split(entrada,\n",
    "                                                                                saida,\n",
    "                                                                                test_size=.3,\n",
    "                                                                                random_state=1234123)\n",
    "\n",
    "    # holdout repetido\n",
    "    for _ in range(repeticoes):\n",
    "        # redefine modelo a cada repeticao\n",
    "        modelo = escolhe_modelo(escolha)\n",
    "\n",
    "        # fit model\n",
    "        modelo.fit(entrada_treino, saida_treino)\n",
    "\n",
    "        # generate predictions\n",
    "        predicao = modelo.predict(entrada_teste)\n",
    "\n",
    "        # calculate accuracy\n",
    "        acerto = accuracy_score(predicao, saida_teste)\n",
    "        # predict probabilities for entrada_teste using predict_proba\n",
    "        probabilities = modelo.predict_proba(entrada_teste)\n",
    "        # select the probabilities for label 1.0\n",
    "        saida_proba = probabilities[:, 1]\n",
    "        # calculate false positive rate and true positive rate at different thresholds\n",
    "        false_positive_rate, true_positive_rate, _ = roc_curve(\n",
    "            saida_teste, saida_proba, pos_label=1)\n",
    "\n",
    "        # calculate AUC\n",
    "        roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "        # MSE\n",
    "        mse = mean_squared_error(saida_teste, predicao)\n",
    "\n",
    "        # guarda resultados\n",
    "        acertos.append(acerto)\n",
    "        aucs.append(roc_auc)\n",
    "        mses.append(mse)\n",
    "        falsos_positivos.append(false_positive_rate)\n",
    "        verdadeiros_positivos.append(true_positive_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-firewall",
   "metadata": {},
   "source": [
    "Depois de terminado, pode-se exibir alguns resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resultados:\\n\")\n",
    "print(f\"Acerto médio: {np.average(acertos)} (+-{np.std(acertos)})\")\n",
    "print(f\"AUC médio: {np.average(aucs)} (+-{np.std(aucs)})\")\n",
    "print(f\"MSE médio: {np.average(mses)} (+-{np.std(mses)})\")\n",
    "melhor_rodada = np.argmax(acertos)\n",
    "print(\"Melhor rodada: \", melhor_rodada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-major",
   "metadata": {},
   "source": [
    "E também o plot de ROC da melhor rodada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Receiver Operating Characteristic')\n",
    "# plot the false positive rate on the x axis and the true positive rate on the y axis\n",
    "plt.plot(falsos_positivos[melhor_rodada],\n",
    "         verdadeiros_positivos[melhor_rodada],\n",
    "         label='AUC = {:0.2f}'.format(roc_auc))\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.plot([0, 1], [0, 1], ls='--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
